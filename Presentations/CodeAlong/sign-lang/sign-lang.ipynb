{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Code Along - Tensorflow and OpenCV (DNN, Dropout, Hyperparameters)\n",
    "\n",
    "This Code Along will introduces using Tensorflow with the OpenCV library for computer vision. In this code along, we will:\n",
    "\n",
    "- Extract/Load JPEG images using OpenCV\n",
    "- Design Deep Neural Network (DNN) with a dropout layer.\n",
    "- Run DNN with different hyperparameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping (Download/Install)\n",
    "If you haven't already, you will need to install Tensorflow Jupyter notebook, OpenCV for Python, as well as Python. I recommend Python 3.\n",
    "\n",
    "For those on Windows 10, you should install Python 3.5 (not 3.6). The Google support blogs still show people continuing to have incompatibility problems with TensorFlow and Python 3.6.\n",
    "\n",
    "If you already have Python 3.6 loaded, try importing tensorflow first and see if the import is successfully, before deciding to downgrade to 3.5\n",
    "You should also be using pip version 9. If you are using an older version, you may need to upgrade.\n",
    "\n",
    "### Python 3.5\n",
    "\n",
    "You can download Python 3.5 here. Goto the bottom of the page and select the download for your OS.\n",
    "\n",
    "https://www.python.org/downloads/release/python-350/\n",
    "\n",
    "If you are not sure which version you have, do the following:\n",
    "\n",
    "C:> python --version\n",
    "\n",
    "<span style='color:red; font-weight:bold'>NOTE: If you have Python 2 and 3 installed, then wherever I have python on the command line, replace with python3</span>\n",
    "\n",
    "### PIP \n",
    "\n",
    "To upgrade to the latest verson of PIP (version 9 as of this writing), do the following (below is an example on Windows command prompt).\n",
    "\n",
    "C:> python -m pip install --upgrade pip \n",
    "\n",
    "If you are not sure which version you have, do the following:\n",
    "\n",
    "C:> pip --version\n",
    "\n",
    "### Tensorflow\n",
    "\n",
    "You want to install Tensorflow 1.6 for your platform. Your platform is a combination of your version of python (e.g., cp35) and your OS/Architecture (e.g., cp35m-win_amd64). \n",
    "\n",
    "You can find the wheels (.whl) install files for Tensorflow 1.6 here:\n",
    "\n",
    "https://pypi.python.org/pypi/tensorflow\n",
    "\n",
    "On my laptop (Win10), I am using:\n",
    "\n",
    "tensorflow-1.6.0rc1-cp35-cp35m-win_amd64.whl\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "You can install Juypter Notebook as follows:\n",
    "\n",
    "C:> python -m pip install jupyter\n",
    "\n",
    "\n",
    "### OpenCV\n",
    "\n",
    "You can install OpenCV for Python as follows:\n",
    "\n",
    "C:> pip install opencv-python\n",
    "\n",
    "<b style='color:red'>NOTE: Do not follow old Python 2.7 instructions (2012). You will download 750Mb and do a bunch of steps.</b>\n",
    "\n",
    "\n",
    "### Putting it Together\n",
    "\n",
    "Let's see if everything is installed correctly:\n",
    "\n",
    "    1. Start python interpreter (REPL) on the command line\n",
    "    2. Type in import tensorflow\n",
    "    3. Type in import cv2\n",
    "    4. There should be no errors in loading the libraries.\n",
    "    \n",
    "### Launch Jupyter Notebook\n",
    "\n",
    "From a command terminal, enter:\n",
    "\n",
    "C:> jupyter notebook\n",
    "\n",
    "This will launch a Jupyter notebook in a web browser (whatever is your default web browser). \n",
    "\n",
    "#### Create a Notebook\n",
    "\n",
    "Under the toolbar, select:\n",
    "\n",
    "File-> New Notebook -> Python 3\n",
    "\n",
    "A notebook will appear which will look similar to this.\n",
    "\n",
    "#### Import Tensorflow and OpenCV\n",
    "\n",
    "In the first input cell, we will import the tensorflow and opencv libraries to verify they are properly installed.\n",
    "\n",
    "Python execution of the cell should complete without any errors. You may get deprecated warnings, just ignore them. Let me try it below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing Tensorflow\n",
    "import tensorflow as tf\n",
    "# Importing OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a few more libraries, so let's load them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "Github Public Repository - https://github.com/EvilPort2/Sign-Language\n",
    "\n",
    "<i>\"The first thing I did was, I created 10 gesture samples using OpenCV. For each gesture I captured 1200 images which were 50x50 pixels. All theses images were in grayscale which is stored in the gestures/ folder. The gestures/0/ folder contains 1200 blank images which signify \"none\" gesture. Also I realised that keeping this category increased my model's accuracy to 99% from a laughable 82%.\"</i>\n",
    "\n",
    "Let's go to the downloaded images and see what's there. Let's first check that we are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Desktop\\\\AITraining\\\\Portland-Data-Science-Group\\\\Presentations\\\\CodeAlong\\\\sign-lang'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see under the gestures directory, we have folders 0 through 26. Folder 0 is the none image, while folders 1 through 26 have images for the letters A..Z, respectively.\n",
    "\n",
    "Let's look under one of the folders (i.e., folder 1 for the letter A):\n",
    "\n",
    "<img src='gestures.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use openCV's method imread to read in a JPEG image and convert it to an uncompressed numpy 2D matrix of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gestures/1/1.jpg\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the image is a numpy matrix as expected. It's type should be numpy.ndarray and it's shape should be 50 x 50 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "print( type(image) )\n",
    "print( image.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the contents of the image. As you can see, it is a matrix of values between 0 and 255 (uint8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting an Image\n",
    "\n",
    "Let's plot one of the images in the training set. To do so, we will use the plotting functions of the matplotlib package. Let's start by importing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This line is specific to python notebooks (not python). \n",
    "# It causes plots to automatically be rendered (displayed) without issuing a show command.\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fc7a847b00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc77eabe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot it now\n",
    "plt.imshow( image )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "The function below traverses the gestures folder for each subfolder (letter in the alphabet) and loads the images and corresponding label (letter), which is obtained from the subfolder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset( verbose = False ):\n",
    "    \"\"\" Load the Sign Language dataset for the Alphabet \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Process each subfolder (0..26) in the gestures folder\n",
    "    for subfolder in os.listdir(\"gestures\"):\n",
    "        if verbose == True: print(\"Loading Subfolder\", subfolder)\n",
    "        # There are 1200 images per letter\n",
    "        for i in range(1200):\n",
    "            # Read each image in\n",
    "            image = cv2.imread(\"gestures/\"+ subfolder + \"/\" + str(i+1) + \".jpg\", 0)\n",
    "            # if bad image, skip\n",
    "            if np.any(image == None):\n",
    "                continue\n",
    "            # add image to image list\n",
    "            images.append( image )\n",
    "            # add corresponding label to label list\n",
    "            labels.append( subfolder )\n",
    "    # return the list of images and corresponding labels\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the images. We will set the parameter verbose to True to see the progress since this will take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Subfolder 0\n",
      "Loading Subfolder 1\n",
      "Loading Subfolder 10\n",
      "Loading Subfolder 11\n",
      "Loading Subfolder 12\n",
      "Loading Subfolder 13\n",
      "Loading Subfolder 14\n",
      "Loading Subfolder 15\n",
      "Loading Subfolder 16\n",
      "Loading Subfolder 17\n",
      "Loading Subfolder 18\n",
      "Loading Subfolder 19\n",
      "Loading Subfolder 2\n",
      "Loading Subfolder 20\n",
      "Loading Subfolder 21\n",
      "Loading Subfolder 22\n",
      "Loading Subfolder 23\n",
      "Loading Subfolder 24\n",
      "Loading Subfolder 25\n",
      "Loading Subfolder 26\n",
      "Loading Subfolder 3\n",
      "Loading Subfolder 4\n",
      "Loading Subfolder 5\n",
      "Loading Subfolder 6\n",
      "Loading Subfolder 7\n",
      "Loading Subfolder 8\n",
      "Loading Subfolder 9\n",
      "Time to Load Images:  70.56759142875671\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "images, labels = load_dataset( True )\n",
    "print( \"Time to Load Images: \", time.time() - start )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see we got what we expected. There are 27 folders (26 letters and None) with 1200 images each. We should have a list of 32,400 (27 * 1200) numpy 2D matrixes (aka the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400\n"
     ]
    }
   ],
   "source": [
    "print( len(images) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify that the images (and labels) we read in by plotting one of the images and it's corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFrVJREFUeJzt3XuMnNV5BvDn2fV6bUO4OAVkvA42xE5BIjHg2KigiBqQjePYtKEthAa3cuqqSiuiJg0mUasiVS20VSB/AIm5NG5DMQmhwnItXMvBommRzYINAVxsYxTwpZgKLC4Wy3r37R/zGeac7+yes9/Ozsxynp+02j3ffpezM/PuN+edc6GZQUTy0tHqCohI8ynwRTKkwBfJkAJfJEMKfJEMKfBFMqTAF8mQAl8kQ6MKfJKLSb5Eci/J1Y2qlIiMLVbtuUeyE8BuAFcC2A/gKQDXmdmLQx0zkd02CSdUup5ICVnelnlP1PfxHj6wvsAD45owimvMB7DXzPYBAMl1AJYDGDLwJ+EELODlo7hkJjo63fLgQPyYsQqC0HlHqmo9/Gt752F3d/lSfX0Nv05QledorOpSZ5ttSdpvNG/1pwN4ra68v9gmIm1uNHf80K2g9O+J5CoAqwBgEqaM4nIi0iijCfz9AGbUlXsAHPR3MrM1ANYAwEmcmncDLFWVt/aht4SjfNsIALvv+rx7yv7y//uzNg465YmPPeXu4L8tBsp/Y8o+3t+T9LY+5TGo0hSxwWF/zQnx0LJjx+J1acBzGDKat/pPAZhNchbJiQCuBbC+IbUSkTFV+Y5vZsdI/imATQA6AdxvZi80rGYiMmZG81YfZrYRwMYG1UVEmkQ990QyNKo7voyRUKLLF0l8AQAndDnl/i+c75S3/Mt90cscHdzulKd0TCzt0/flfqfcza7SPjEXPf27pW1vHjzZKc/5Yy9p2Ki+C1USaH6fAi+ZF0zcxa6beu0G0B1fJEMKfJEMKfBFMlR5kE4VJ3Gqqa9+BSmdWwI2HdzplAe8TiedLP/f77ORt9dj5/V/X3Wf2HUB4NOPrXLKc1b2DnuOIP/xDnXWiXS04cRyLqRhHY6Gsc224G17MzrAQnd8kQwp8EUypMAXyZA+x28HsTHvofa81w499T9PLu1ydPADp9zN+NPtt+n7zb12F8v5hkF/UGZCLiHlvLF9Qud95ap73Q2lYWNl52z5Q6f86Rvc3EiwnR0Zjx9szye039npnjepP0AFuuOLZEiBL5IhBb5IhhT4IhlScq8dxGZdCQ7mcBNo955VHh09pWPSaGtWSqj5HXyAaoNy/POGOuP4+/jJvpTz+gnO0CCjly//J/c6++OJx0VnznXK7HLPa/3udWs7effZwN9TSua14Qw8IjJOKfBFMqTAF8mQ2vhtINo+TBikc2KgPR/rABNqr0/A8J1k/N+nqJoXSGmfx/jHpAwG6gjOHO/acOBpp3zh9q865TN/a8h1ZT7kP+9A+bkfqw49uuOLZEiBL5IhBb5IhhT4IhlScq8NlBI6KTO2JqxiG0tShRJsoeRXvdCIuNgMPCnXCZ13CodP5lXp0BOSUpfYeX+54F+d8h9tu6R0zKsL3nPKFnmsAY3OE5EGUuCLZEiBL5KhfNv4CW3khixZXGE565R23bHfvNAp91t5NtnYQJhQWzalfduqY3wp7fexuG6I/9jeM+O/Svssgjuwp1EDbpycUGJKQHd8kQwp8EUypMAXyVC+bfyE9lVp8MyA97lxwufIpVVVu7vLu/gzskZmcAWALT92V7rtD/w5jVjhRtIeJ78c6mPgr2zkT+YBoFIeyQbr9klMG+hZFsmQAl8kQ9HAJ3k/ycMkn6/bNpXkZpJ7iu+njm01RaSRUu74PwKw2Nu2GsAWM5sNYEtRFpFxIprcM7MnSM70Ni8HcFnx81oAWwHc1MB6NV+gQ48d82aOSelw0Yillbxj/KRQSEpnlkbMaCNpQgOkSgm/lE5kpRmXA/fqhME+vqpt/DPM7BAAFN9Pr3geEWmBMf84j+QqAKsAYBKmjPXlRCRB1Tv+6ySnAUDx/fBQO5rZGjObZ2bzulD+DFtEmq/qHX89gBUAbi2+P9qwGjVLSkcJv72e0kbzO9skdMaZuc2dIfeHPU+Wz+vxZ67tCPwP99uZatNXE+rUFMuXBAdAeeW/3bettM93zl7gbvBflymdxhKkfJz3IIAnAXyG5H6SK1EL+CtJ7gFwZVEWkXEiJat/3RC/urzBdRGRJlHPPZEM5TtIJ0WgPV7PX+UECEyiUeEz+ZQJM/wJLEODQmIDbhq18m2OuumGTmzVopBzAw/1y39/sVM+5y+8fE/ss38N0hGRoSjwRTKkwBfJkAJfJEP5JvdiM+iGeMmylBVuNh3Y4ZRDCTW/802V2WNDx8Q6mSiRl8Z/HIFAZygvIRs6xk8IhjpUvfSVO53yuQNfd8qzVsc7d6XQHV8kQwp8kQwp8EUylG8b35cySMfv0BPKC0Qm66jSrq46G67fpvSpA0+aUFvcf+z8xy220i+Q9rzuvuFup7zo5guGP6k68IjIUBT4IhlS4ItkKN82fsIEGUlt+oiUATexfULHxNqYoeM02WbjVMmFpDxnsdeC3y8EABZNj7T7A3THF8mQAl8kQwp8kQwp8EUy1PzkXn1SLTLDDQBwglvF4MCYKrxr+9cJXqvCwJ6Ujjb+PilJoNCsuj4/UVRl8I80TkpCMPZ6CXX6qUJ3fJEMKfBFMqTAF8lQ89v4sZlrY216v+NNwjmDvPMk5Q5SVt/x9klpr5eqlvD/OKW9XuoI5P0+NDOv8gDtLSVnlEJ3fJEMKfBFMqTAF8lQawfpBNrrpba2364Otee9fTih3I62fm/yw4QBOP5KOVXyDct65jvljfufLh/izZ7gt7NDbfFBuJ/nTii14OPUnv+YiEz+EqI7vkiGFPgiGVLgi2RIgS+SoeYm9+h20Kk04CYhoVZK5AHxzjeBBIkNRpImCYlG/7xLZny+dMgmL+GXsuTygLnXCXXs8M/TAfeYqrP3SnthV91MSv1ps0TpWRbJkAJfJEPRwCc5g+TjJHeRfIHkjcX2qSQ3k9xTfD917KsrIo2Q0sY/BuCbZvYMyU8AeJrkZgB/AGCLmd1KcjWA1QBuGvZMltCuj7bFEwbkVFjhxmknHT/EzxUkDdLx/5d67ehAXmDRmXOd8voDTzllvz0PxCfvALQqzsfRrI1fK22b09/7USGxM0/0jm9mh8zsmeLndwDsAjAdwHIAa4vd1gK4OumKItJyI2rjk5wJ4AIA2wCcYWaHgNo/BwCnN7pyIjI2kgOf5IkAfgbgG2b29giOW0Wyl2RvP/qq1FFEGiwp8El2oRb0D5jZI8Xm10lOK34/DcDh0LFmtsbM5pnZvC50N6LOIjJK0eQeSQK4D8AuM/te3a/WA1gB4Nbi+6NJV6zrgMOOctIqlvxLSsKNsB7J54gl7oCGLLu1/OxLnfJjr2yLHhNK5MU6AmkGnnEodKuufy0nTkaVktW/BMBXAfyS5M5i23dQC/ifkFwJ4FUAv5N2SRFptWjgm9kvAAx127q8sdURkWZQzz2RDLV0lt0qi4LYsXJHlfJOCZ0Yqlw8ZTbf2PLboTa/lzuwPvfTjy/8yarSIZvvutMph2bg8dvrVWb8lXGgwizTuuOLZEiBL5IhBb5Ihprfxq9r4+6+uzwpxSvL1gx7eGjyCH+W2qXTLxr2ugDKeYAKK/QkrbBb2iGQf/A/T/fqOnm9O2gHACbc5dY3NIGG/1ipTT/+zVlZnqW5Ct3xRTKkwBfJkAJfJEMKfJEMNTW51zfjBOy56aMlpV5Z9sPSPrGBJcFZYL0k1sYDz5R28Y/zE19fuuL3SscM7NpTvlb9ZUOJvFgHngpJxL4l80rbOrnDKVeZMVez7OZLz7JIhhT4IhlS4ItkqKlt/PNPfQPbv/xRuz5lIogqA0tSVpXxr/Pw5gdKx0zpcCf9CNXXt7THbY/7nXxSVg86tvBCp7z1nnuix/idmABgsEq+RMafChNx6JkXyZACXyRDCnyRDDV/kE6d8Cqw7mfLHQ363+Rfy7+O356vcg4AWL9/u1OuMjDm6KB7jgGLP01VJsnU5/jjUMogrwR6lkUypMAXyZACXyRDCnyRDDU1ubf7uSnOktCbDu4s7eMnl/yUVUpC6uhgeVWcbrp/akoSq8qAoc7I/9KU5az9RGPVJJx/LX8mXiXyPh6cTmLx/mEAdMcXyZICXyRDCnyRDLW0A8+i6ReUtj3w6i+c8skdk5xySkeVlM44vpS297uD7zvlE726pZw3pUNPyjEp+2hW3Tw4A78SFpECdMcXyZICXyRDCnyRDDW3jU/3M8fQpBTXf+pS7xj3f9O/vfpk6Zgqn3unrDLjf47vt+lT8gKxPEHKMSkTgIT49fMHPFUZ2CMtFpqstZ4m4hCRoSjwRTIUDXySk0huJ/ksyRdI3lJsn0VyG8k9JB8iOfLP0ESkJVLu+H0AFprZ5wDMBbCY5MUAbgNwu5nNBvAWgJVjV00RaaRocs/MDMC7RbGr+DIACwF8pdi+FsBfA7h7+JN5CT1/6eraBb2ym6347Zm/UT7ESxKuP1BeVtofPOMn+0KJOn9QS0pC0N/Hn/02pdOPP8golITzrx1KaMaSeZqBZ/zZvabc6W3O13pHfJ6kZ5lkJ8mdAA4D2AzgZQBHzOx4xO0HMH3EVxeRlkgKfDMbMLO5AHoAzAdwbmi30LEkV5HsJdnbj77qNRWRhhnR+zozOwJgK4CLAZxCfjjIvQfAwSGOWWNm88xsXhe6R1NXEWmQaBuf5GkA+s3sCMnJAK5ALbH3OIBrAKwDsALAoyO+enDl2+F7IARXovFyBct65pf38XIHq3bvc4854a3SIbH2bspKQCkTicTOEWrjxybZCB0Xm1hExoFAWqzKSjopPfemAVhLshO1dwg/MbMNJF8EsI7k3wDYAeC+tEuKSKulZPWfA1BKJZrZPtTa+yIyzuizG5EMKfBFMtTSGXgwWG3UWUloWaGINXPOdsuhUU+R+l33P+UPMq77xAGnXGlm24QEoC/lvB3BzNDIhBKa/nmrdI5Sx6FEoaewQhzp0RbJkAJfJEMKfJEMtbaN30p+mz7QTmK329PQ+twuxw/++pmlYx6kN2TBb7sGrtMx9zyn/PsPbXLK1574RumYlBl0/c5CjVg9KKXTT8oMwCkdmSRg5OmsIN3xRTKkwBfJkAJfJEP5tvETPvv02/TRGU5TrhOYfGRw54tO+Z8/M8Mtwy0HzxPqy+Dts/C5d53yt6a+VDqkysCe2AQlKYOZQiscV1kRKUfsqnuc+tP6auiOL5IhBb5IhhT4IhlS4ItkKNvknpMQAWD95eRSKYHWiEFFCQOKkurmnyeQNGSnm0D7+fknuGVeFK3Lhv3xGVz9jkFVZvpRIi9R4OXjvD4SB6zpji+SIQW+SIYU+CIZyraNH2w3l3aKtKND7Sm/k48/GCVhoIwd8yauSFpxqFwXf0bi+iXKAcAGAjkL7zxfOmuBU/7Vd8vTLO5c9X2nHJrx1+cvFz45sPSiJucICPXPqX99JA7i0SMrkiEFvkiGFPgiGcq2jd+Q9npI7LP+yEpBqUqThPQHVhjy6hJchcjn/c3+MZ+65b9Lhzx5g1uXyybHH6eUVYMlYDDSX0NtfBEZigJfJEMKfJEMKfBFMpRvcs9P5qWspBPqSOOLzd4buA473POWknCBY0qzA6XUxU9OhhKaseRk4DH4u3M+65QvO7jTKafMwBNabSdlJuHczJx5uLTNeb0ouSciQ1Hgi2RIgS+SoXzb+L5Q2zZhtZ3oeRLOEe0XFNohpQNSrE2fMvinAUITcaSstiNl/3HeI6VtSznvo4La+CIyFAW+SIaSA59kJ8kdJDcU5Vkkt5HcQ/IhMjCgWkTa0kja+DcC2AXgpKJ8G4DbzWwdyR8AWAng7gbXr7UaMblmkyborHTcGLTnAeDfj7oDcBZPPlrap8pqOwJ0hGbiqDBhSdIRJHsAfBHAvUWZABYCeLjYZS2Aq0d8dRFpidR/FXcA+DaA42niTwI4YmbHuwztBzA9dCDJVSR7Sfb2I6G3mYiMuWjgk1wK4LCZPV2/ObBr8H2jma0xs3lmNq8L3aFdRKTJUtr4lwBYRnIJgEmotfHvAHAKyQnFXb8HwMGxq6aINFI08M3sZgA3AwDJywB8y8yuJ/lTANcAWAdgBYBHx7Ce0iwpHYMi/vLF5U75iot+XNqn03uzqURemuDMwxUSyKP5HP8mAH9Oci9qbf77RnEuEWmiEXXZNbOtALYWP+8DUJ5kXUTannruiWRIg3TE1YBOP6cte8kpdx8sD8AZSJixWCvplIU6OlWhR1YkQwp8kQwp8EUypDa+DC9lgtHIxKWhdqk/2ETt+TSh/g7OKsgJiyUBuuOLZEmBL5IhBb5IhhT4IhlSck+G5yfdUgaEeJ1zlk6/qLTLJm+1HalOK+mISBIFvkiGFPgiGVIbX1yRlX+cziIFG/Da/Qkr9qx/b4pTvmrKO6V9NDlHGnbVzWzfn9DhCrrji2RJgS+SIQW+SIYU+CIZUnJPXH4yr8tdEtH6P4ifI2Fp8Dtnz3HKy9ShJ0lopOPuf7zww5/7/uGJpPPoji+SIQW+SIYU+CIZoo3RUskhJ3GqLeDlTbueNF6wA8+g9xpqxNLg0ECekNDsxPWzF81f9Bp6n30/2otHd3yRDCnwRTKkwBfJkD7HlxFxJn0YY4vOnOuU99y5wK1LR4PyU81Lc425/z3y/aT9dMcXyZACXyRDCnyRDCnwRTKk5J60L2+wz+w/63V/36COQqUZgprYqa3R3rKjSfvpji+SIQW+SIYU+CIZauogHZJvAPgVgF8D8H9Nu/DojKe6AuOrvuOprsD4qO9ZZnZabKemBv6HFyV7zWxe0y9cwXiqKzC+6jue6gqMv/oOR2/1RTKkwBfJUKsCf02LrlvFeKorML7qO57qCoy/+g6pJW18EWktvdUXyVBTA5/kYpIvkdxLcnUzr52C5P0kD5N8vm7bVJKbSe4pvp/ayjoeR3IGycdJ7iL5Askbi+3tWt9JJLeTfLao7y3F9lkktxX1fYjkxNi5moVkJ8kdJDcU5bat60g1LfBJdgK4E8BVAM4DcB3J85p1/UQ/ArDY27YawBYzmw1gS1FuB8cAfNPMzgVwMYCvF49nu9a3D8BCM/scgLkAFpO8GMBtAG4v6vsWgJUtrKPvRgC76srtXNcRaeYdfz6AvWa2z8w+ALAOwPImXj/KzJ4A8Ka3eTmAtcXPawFc3dRKDcHMDpnZM8XP76D2Ap2O9q2vmdm7RbGr+DIACwE8XGxvm/qS7AHwRQD3FmWiTetaRTMDfzqA1+rK+4tt7e4MMzsE1IINwOktrk8JyZkALgCwDW1c3+Kt804AhwFsBvAygCNmdnw+r3Z6TdwB4NsAjs9n/Um0b11HrJmBH5rrWx8pjBLJEwH8DMA3zOztVtdnOGY2YGZzAfSg9g7w3NBuza1VGcmlAA6b2dP1mwO7tryuVTVzPP5+ADPqyj0ADjbx+lW9TnKamR0iOQ21u1VbINmFWtA/YGaPFJvbtr7HmdkRkltRy02cQnJCcSdtl9fEJQCWkVwCYBKAk1B7B9COda2kmXf8pwDMLjKjEwFcC2B9E69f1XoAK4qfVwB4tIV1+VDR5rwPwC4z+17dr9q1vqeRPKX4eTKAK1DLSzwO4Jpit7aor5ndbGY9ZjYTtdfpz83serRhXSszs6Z9AVgCYDdqbbvvNvPaifV7EMAhAP2ovUNZiVrbbguAPcX3qa2uZ1HXS1F7q/kcgJ3F15I2ru9nAewo6vs8gL8qtp8NYDuAvQB+CqC71XX16n0ZgA3joa4j+VLPPZEMqeeeSIYU+CIZUuCLZEiBL5IhBb5IhhT4IhlS4ItkSIEvkqH/B0g6zDs0WbkxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc7fbfdd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot it now\n",
    "index = 2407\n",
    "plt.imshow( images[index] )\n",
    "print (\"y = \" + str(labels[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten and Normalize the Image Data\n",
    "\n",
    "Now we will flatten the data (reshape so all rows follow each other sequential in a single vector) and normalize the pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-415d39a3b037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Flatten the Image Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimages_flatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Normalize the Pixel Values between 0 and 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_flatten\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Flatten the Image Data\n",
    "images_flatten = images.reshape(images.shape[0], -1).T\n",
    "\n",
    "# Normalize the Pixel Values between 0 and 1\n",
    "images = images_flatten / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
