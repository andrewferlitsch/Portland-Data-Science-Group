{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Code Along - Tensorflow and OpenCV (DNN, Dropout, Hyperparameters)\n",
    "\n",
    "This Code Along will introduces using Tensorflow with the OpenCV library for computer vision. In this code along, we will:\n",
    "\n",
    "- Extract/Load JPEG images using OpenCV\n",
    "- Design Deep Neural Network (DNN) with a dropout layer.\n",
    "- Run DNN with different hyperparameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping (Download/Install)\n",
    "If you haven't already, you will need to install Tensorflow Jupyter notebook, OpenCV for Python, numpy and scikit-learn libraries, as well as Python. I recommend Python 3.\n",
    "\n",
    "For those on Windows 10, you should install Python 3.5 (not 3.6). The Google support blogs still show people continuing to have incompatibility problems with TensorFlow and Python 3.6.\n",
    "\n",
    "If you already have Python 3.6 loaded, try importing tensorflow first and see if the import is successfully, before deciding to downgrade to 3.5\n",
    "You should also be using pip version 9. If you are using an older version, you may need to upgrade.\n",
    "\n",
    "### Python 3.5\n",
    "\n",
    "You can download Python 3.5 here. Goto the bottom of the page and select the download for your OS.\n",
    "\n",
    "https://www.python.org/downloads/release/python-350/\n",
    "\n",
    "If you are not sure which version you have, do the following:\n",
    "\n",
    "C:> python --version\n",
    "\n",
    "<span style='color:red; font-weight:bold'>NOTE: If you have Python 2 and 3 installed, then wherever I have python on the command line, replace with python3</span>\n",
    "\n",
    "### PIP \n",
    "\n",
    "To upgrade to the latest verson of PIP (version 9 as of this writing), do the following (below is an example on Windows command prompt).\n",
    "\n",
    "C:> python -m pip install --upgrade pip \n",
    "\n",
    "If you are not sure which version you have, do the following:\n",
    "\n",
    "C:> pip --version\n",
    "\n",
    "### Numpy and Scikit-Learn\n",
    "\n",
    "To install the numpy and scikit-learn libraries for Python, do the following:\n",
    "\n",
    "C:> pip install numpy, scikit-learn\n",
    "\n",
    "### Tensorflow\n",
    "\n",
    "You want to install Tensorflow 1.6 for your platform. Your platform is a combination of your version of python (e.g., cp35) and your OS/Architecture (e.g., cp35m-win_amd64). \n",
    "\n",
    "You can find the wheels (.whl) install files for Tensorflow 1.6 here:\n",
    "\n",
    "https://pypi.python.org/pypi/tensorflow\n",
    "\n",
    "On my laptop (Win10), I am using:\n",
    "\n",
    "tensorflow-1.6.0rc1-cp35-cp35m-win_amd64.whl\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "You can install Juypter Notebook as follows:\n",
    "\n",
    "C:> python -m pip install jupyter\n",
    "\n",
    "\n",
    "### OpenCV\n",
    "\n",
    "You can install OpenCV for Python as follows:\n",
    "\n",
    "C:> pip install opencv-python\n",
    "\n",
    "<b style='color:red'>NOTE: Do not follow old Python 2.7 instructions (2012). You will download 750Mb and do a bunch of steps.</b>\n",
    "\n",
    "\n",
    "### Putting it Together\n",
    "\n",
    "Let's see if everything is installed correctly:\n",
    "\n",
    "    1. Start python interpreter (REPL) on the command line\n",
    "    2. Type in import tensorflow\n",
    "    3. Type in import cv2\n",
    "    4. There should be no errors in loading the libraries.\n",
    "    \n",
    "### Launch Jupyter Notebook\n",
    "\n",
    "From a command terminal, enter:\n",
    "\n",
    "C:> jupyter notebook\n",
    "\n",
    "This will launch a Jupyter notebook in a web browser (whatever is your default web browser). \n",
    "\n",
    "#### Create a Notebook\n",
    "\n",
    "Under the toolbar, select:\n",
    "\n",
    "File-> New Notebook -> Python 3\n",
    "\n",
    "A notebook will appear which will look similar to this.\n",
    "\n",
    "#### Import Tensorflow and OpenCV\n",
    "\n",
    "In the first input cell, we will import the tensorflow and opencv libraries to verify they are properly installed.\n",
    "\n",
    "Python execution of the cell should complete without any errors. You may get deprecated warnings, just ignore them. Let me try it below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-rc1\n",
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Importing Tensorflow\n",
    "import tensorflow as tf\n",
    "print( tf.__version__ )\n",
    "\n",
    "# Importing OpenCV\n",
    "import cv2\n",
    "print( cv2.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a few more libraries, so let's load them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "Github Public Repository - https://github.com/EvilPort2/Sign-Language\n",
    "\n",
    "<i>\"The first thing I did was, I created 10 gesture samples using OpenCV. For each gesture I captured 1200 images which were 50x50 pixels. All theses images were in grayscale which is stored in the gestures/ folder. The gestures/0/ folder contains 1200 blank images which signify \"none\" gesture. Also I realised that keeping this category increased my model's accuracy to 99% from a laughable 82%.\"</i>\n",
    "\n",
    "Let's go to the downloaded images and see what's there. Let's first check that we are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Desktop\\\\AITraining\\\\Portland-Data-Science-Group\\\\Presentations\\\\CodeAlong\\\\sign-lang'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see under the gestures directory, we have folders 0 through 26. Folder 0 is the none image, while folders 1 through 26 have images for the letters A..Z, respectively.\n",
    "\n",
    "Let's look under one of the folders (i.e., folder 1 for the letter A):\n",
    "\n",
    "<img src='gestures.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use openCV's method imread to read in a JPEG image and convert it to an uncompressed numpy 2D matrix of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gestures/1/1.jpg\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the image is a numpy matrix as expected. It's type should be numpy.ndarray and it's shape should be 50 x 50 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "print( type(image) )\n",
    "print( image.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the contents of the image. As you can see, it is a matrix of values between 0 and 255 (uint8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting an Image\n",
    "\n",
    "Let's plot one of the images in the training set. To do so, we will use the plotting functions of the matplotlib package. Let's start by importing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This line is specific to python notebooks (not python). \n",
    "# It causes plots to automatically be rendered (displayed) without issuing a show command.\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200f8b25e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200f619c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot it now\n",
    "plt.imshow( image )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "The function below traverses the gestures folder for each subfolder (letter in the alphabet) and loads the images and corresponding label (letter), which is obtained from the subfolder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset( verbose = False ):\n",
    "    \"\"\" Load the Sign Language dataset for the Alphabet \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Process each subfolder (0..26) in the gestures folder\n",
    "    for subfolder in os.listdir(\"gestures\"):\n",
    "        if verbose == True: print(\"Loading Subfolder\", subfolder)\n",
    "        # There are 1200 images per letter\n",
    "        for i in range(1200):\n",
    "            # Read each image in\n",
    "            image = cv2.imread(\"gestures/\"+ subfolder + \"/\" + str(i+1) + \".jpg\", 0)\n",
    "            # if bad image, skip\n",
    "            if np.any(image == None):\n",
    "                continue\n",
    "            # add image to image list\n",
    "            images.append( image )\n",
    "            # add corresponding label to label list\n",
    "            labels.append( subfolder )\n",
    "    # return the list of images and corresponding labels\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the images. We will set the parameter verbose to True to see the progress since this will take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Subfolder 0\n",
      "Loading Subfolder 1\n",
      "Loading Subfolder 10\n",
      "Loading Subfolder 11\n",
      "Loading Subfolder 12\n",
      "Loading Subfolder 13\n",
      "Loading Subfolder 14\n",
      "Loading Subfolder 15\n",
      "Loading Subfolder 16\n",
      "Loading Subfolder 17\n",
      "Loading Subfolder 18\n",
      "Loading Subfolder 19\n",
      "Loading Subfolder 2\n",
      "Loading Subfolder 20\n",
      "Loading Subfolder 21\n",
      "Loading Subfolder 22\n",
      "Loading Subfolder 23\n",
      "Loading Subfolder 24\n",
      "Loading Subfolder 25\n",
      "Loading Subfolder 26\n",
      "Loading Subfolder 3\n",
      "Loading Subfolder 4\n",
      "Loading Subfolder 5\n",
      "Loading Subfolder 6\n",
      "Loading Subfolder 7\n",
      "Loading Subfolder 8\n",
      "Loading Subfolder 9\n",
      "Time to Load Images:  106.8585114479065\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "images, labels = load_dataset( True )\n",
    "print( \"Time to Load Images: \", time.time() - start )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see we got what we expected. There are 27 folders (26 letters and None) with 1200 images each. We should have a list of 32,400 (27 * 1200) numpy 2D matrixes (aka the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400\n"
     ]
    }
   ],
   "source": [
    "print( len(images) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify that the images (and labels) we read in by plotting one of the images and it's corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200f8b6bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot it now\n",
    "index = 2407\n",
    "plt.imshow( images[index] )\n",
    "print (\"y = \" + str(labels[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the Image Data\n",
    "\n",
    "Now we will flatten the data (reshape so all rows follow each other sequential in a single vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images as Numpy Array: (32400, 50, 50)\n",
      "Images Flatten: (32400, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Convert python list to numpy array\n",
    "images_np = np.asarray(images)\n",
    "print( \"Images as Numpy Array:\", images_np.shape )\n",
    "\n",
    "images_flatten = images_np.reshape(images_np.shape[0], -1)\n",
    "print( \"Images Flatten:\", images_flatten.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Image Data\n",
    "\n",
    "Now we will normalize the pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Pixel Values between 0 and 1\n",
    "x = images_flatten / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Conversion of Labels\n",
    "\n",
    "Let's now convert the labels from a categorical value to a one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels as Numpy Array: (32400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', ..., '9', '9', '9'], dtype='<U2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert python list to numpy array\n",
    "labels_np = np.asarray(labels)\n",
    "print( \"Labels as Numpy Array:\", labels_np.shape )\n",
    "\n",
    "# Let's look at the array data type\n",
    "labels_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an unsigned 64bit integer. For our purposes we need it as a signed integer. Let's change its datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_int = labels_np.view('int64')\n",
    "labels_int[:] = labels_np\n",
    "\n",
    "# Let's look at the new data type\n",
    "labels_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the array shape and data type are ready. Let's do the one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32400, 27)\n"
     ]
    }
   ],
   "source": [
    "def convert_labels_to_one_hot_encoding(Y, C):\n",
    "    \"\"\" This function will do the reshape and conversion (from Coursera)\"\"\"\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "# Let's do the conversion\n",
    "y = convert_labels_to_one_hot_encoding(labels_int, 27)\n",
    "\n",
    "# Let's print the shape of our labels\n",
    "print( y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training and Test Data\n",
    "\n",
    "Now that we have our data and labels ready, let's split our dataset into training and test data. For our purposes, we will use 80% as training and 20% as test. We could do the split by hand using numpy.random.shuffle() to randomize the order, and then use array slicing.\n",
    "\n",
    "But scikit-learn has an all-in-one method for this purpose, so we will use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data/labels into 80% training and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network with Dropout Layer - Softmax Activation\n",
    "\n",
    "We are going to build a simple deep neural network (DNN) with a dropout layer. There will not be a convolutional layer. That is, we will use all 2500 pixels as input. The output layer from our neural network will be passed through a softmax activation function to produce our predictions of the letter.\n",
    "\n",
    "In our Neural Network, we will have the following:\n",
    "\n",
    "    - An input layer of 2500 inputs and 64 outputs\n",
    "    - A linear recitifier activation function\n",
    "    - A first hidden layer of 64 inputs and 32 outputs\n",
    "    - A dropout layer\n",
    "    - A linear recitifier activation function\n",
    "    - A second hidden layer of 32 inputs and 20 outputs\n",
    "    - A linear recitifier activation function\n",
    "    - An output layer of 20 inputs and 27 outputs\n",
    "    - A softmax activation function\n",
    "\n",
    "INPUT LAYER => RELU => HIDDEN LAYER => DROPOUT LAYER => RELU => HIDDEN LAYER => RELU => OUTPUT LAYER => SOFTMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "We will use the softmax layer to make our predictions. Each output from softmax will be a number between 0 and 1, representing a percent. That is, if the output for the node 3 is 0.8, then this means 80% prediction. We will choose the output with the highest percent when making a prediction.\n",
    "\n",
    "Softmax is a mathematical function that takes a set of values, which may otherwise not add up to 1, and outputs a new set of numbers when totaled will add up to 1. That is, we use softmax() so that all our outputs for each image add up to 1 (100%).\n",
    "\n",
    "Softmax will be our 'activation' function from the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your first neural network in TensorFlow\n",
    "\n",
    "### Design, then Run\n",
    "\n",
    "#### Design\n",
    "\n",
    "     -- Create placeholders for your input data\n",
    "     -- Design the layers as a Graph\n",
    "     -- Set the optimizer\n",
    "     \n",
    "#### Run\n",
    "\n",
    "      -- Initialize the Graph\n",
    "      -- Set number of epochs\n",
    "      -- Set batch size, learning rate\n",
    "      -- Run the Graph with the Training Data to Train a Model\n",
    "      -- Validate the Model with Test Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Vector and Output Vector and Hyperparameter Placeholders\n",
    "\n",
    "For our first tensorflow step, we will setup Tensorflow placeholders.\n",
    "\n",
    "We have two placeholders we need to declare, one for the input vector (pixel image data) and one for the output vector (letter classifier).\n",
    "\n",
    "For our input placeholder (which we call X), we have 2,500 features (pixels per image). For the output vector (which we call Y), we have have 27 classifiers (alphabet and None). In both cases, we set the second dimension of our vector to None. The None is a placeholder for the number of samples we will feed into the neural network. We also know that our data is floating point values between 0 and 1, so we will set the data type to float32.\n",
    "\n",
    "We will declare two more placeholders for setting some hyper-parameters, the percent to keep in the dropout layer (D, and the learning rate in the optimizer (L). Since both are scalar values, we will define their shape as a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first reset our graph, so our neural network components are all declared within the same graph\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[2500, None])\n",
    "Y = tf.placeholder(tf.float32, shape=[27, None])\n",
    "D = tf.placeholder(tf.float32, [])\n",
    "L = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT LAYER\n",
    "\n",
    "Let's now design our input layer. We need two things: weights and biases. \n",
    "\n",
    "Each input feature (pixel) will need a weight (which our model will learning during training). The weight is multipled against the value of the input (pixel), which we symbolically represent as Wx. \n",
    "\n",
    "Each output from the layer will need a bias (which our model will learning during training). The bias is added to the result of the weight multipled by the pixel value (Wx).\n",
    "\n",
    "Let's create two Tensorflow variables for our weights and biases. The weights (which we call W) will need to be a 2D matrix. The rows are the number of inputs, which is 2500 and the columns the number of outputs to the hidden layer, which will be 64.\n",
    "\n",
    "The bias will be a vector of size 64 (one for each output).\n",
    "\n",
    "We need to initialize our weights and biases to some initial value. We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)   # Set the same seed to get the same initialization as in this demo.\n",
    "\n",
    "# The weights for the input layer\n",
    "W1 = tf.get_variable(\"W1\", [64, 2500], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "\n",
    "# The bias for the output from the input layer\n",
    "b1 = tf.get_variable(\"b1\", [64, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it together into an input layer. We will use the Tensorflow method tf.matmul() to do a matrix multiplication of the weights (our variable W1) and the inputs (our placeholder X), add in the bias (b1), and pass the output through a linear activation function.\n",
    "\n",
    "- Create a node that will multiply the weights (W1) against the input vector (X - which is our input placeholder).\n",
    "- Create a node that adds the bias to the above node (W1 * X)\n",
    "- Pass the outputs from the input layer through a RELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first layer (input layer)\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "\n",
    "# Let's add the activation function to the output signal from the first layer\n",
    "A1 = tf.nn.relu(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST HIDDEN LAYER\n",
    "\n",
    "The first hidden layer will have 64 inputs (outputs from input layer) and 32 outputs. Each input will need a weight and each output a bias (which we will train). Each output will be passed through the linear rectifier unit (RELU) activation function.\n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"W2\", [32, 64], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b2 = tf.get_variable(\"b2\", [32, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the first hidden layer\n",
    "\n",
    "- Create a node that will multiply the weights (W2) against the outputs of the input layer (A1).\n",
    "- Create a node that adds the bias to the above node (W2 * A1)\n",
    "- Pass the outputs from the (first) hidden layer through a dropout layer\n",
    "- Pass the outputs from the dropout layer through a RELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second layer (first hidden layer)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2) \n",
    "\n",
    "# Let's add the dropout layer to the output signal from the second layer\n",
    "D2 = tf.nn.dropout(Z2, keep_prob=D)\n",
    "\n",
    "# Let's add the activation function to the output signal from the dropout layer\n",
    "A2 = tf.nn.relu(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECOND HIDDEN LAYER\n",
    "\n",
    "The second hidden layer will have 32 inputs (outputs from first hidden layer) and 20 outputs. Each input will need a weight and each output a bias (which we will train). Each output will be passed through the linear rectifier unit (RELU) activation function.\n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", [20, 32], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b3 = tf.get_variable(\"b3\", [20, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the second hidden layer.\n",
    "- Create a node that will multiply the weights (W3) against the outputs of the first hidden layer (A2).\n",
    "- Create a node that adds the bias to the above node (W3 * A2)\n",
    "- Pass the outputs from the second hidden layer through a RELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third layer (second hidden layer)\n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3) \n",
    "\n",
    "# Let's add the activation function to the output signal from the third layer\n",
    "A3 = tf.nn.relu(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT LAYER\n",
    "\n",
    "The output layer will have 20 inputs (outputs from the second hidden layer) and 27 outputs (one for each letter and None). Each input will need a weight and each output a bias (which we will train). The 27 outputs will be passed through a softmax activation function. \n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.get_variable(\"W4\", [27, 20], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b4 = tf.get_variable(\"b4\", [27, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the output layer.\n",
    "\n",
    "- Create a node that will multiply the weights (W4) against the outputs of the second hidden layer (A3).\n",
    "- Create a node that adds the bias to the above node (W4 * A3)\n",
    "- Pass the outputs from the output layer through a SOFTMAX squashing function (done by the optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fourth layer (output layer)\n",
    "Z4 = tf.add(tf.matmul(W4, A3), b4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZER\n",
    "\n",
    "Now its time to design our optimizer. Let's start by designing our cost function. We will use the mean value of the softmax cross entropy between the predicted labels and actual labels. This is what we want to reduce on each batch (aka the cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.transpose(Z4), labels=tf.transpose(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design our optimizer. This is the method that adjusts the values of the weights and biases, based on minizing the cost value during training.\n",
    "\n",
    "We also need to set a learning rate. This is multiplied against the gradient calculation. It's used to prevent huge swings in setting weights which can result in either converging at a local (instead of global) optima, or not converging at all (infinite gradient). We will set the learning rate when we run the graph using the placeholder L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate for Gradient Descent algorithm\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(L).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Graph\n",
    "\n",
    "We've built our Tensorflow graph for training our data. So, let's start training it.\n",
    "\n",
    "First, we need to call Tensorflow's global_variables_initializer() method to initialize the variables we've defined. We will create this as another node, which will be the first node we run (evaluate) in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also a good idea to know how long your training takes, so let's import the time library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's set our hyperparameters.\n",
    "\n",
    "We need to set the number of epochs (that's how many times we run the training data through the neural network), and the batch size. The batch size is a small subset of the entire training set. We will be running a batch at a time per epoch. After each batch, then the cost is computed and backpropagated through the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20                                    # run a 20 epochs\n",
    "batch_size = 100                               # for each epoch, train in batches of 100 images\n",
    "number_of_images = x_train.shape[0]            # number of images in training data\n",
    "batch_size = 200                               # size of each batch\n",
    "batches = number_of_images // batch_size       # number of batches in an epoch\n",
    "\n",
    "# Feed Dictionary Parameters\n",
    "keep_prob = 0.9                                # percent of outputs to keep in dropout layer\n",
    "learning_rate = 0.5                            # the learning rate for graident descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to run the graph now!\n",
    "\n",
    "We start by creating a tensorflow session (tf.Session()). Within the session we can run (evaluate) parts of the graph we designed.\n",
    "\n",
    "We start by initializing the tensor variables we defined for the weights and biases.\n",
    "\n",
    "We then run our training data through our neural network for the number of epochs we defined. For each epoch, we get a randomly shuffled batch from the training data and feed the batch (i.e. feed dictionary) into the neural network by running (evaluate) the optimizer node in our graph.\n",
    "\n",
    "Once we've trained the model, then we create some new nodes to calculate accuracy and evaluate against the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 3.1966683790665265\n",
      "Epoch:  1 2.2554031314775926\n",
      "Epoch:  2 2.0474198465199436\n",
      "Epoch:  3 2.357694100963977\n",
      "Epoch:  4 2.0568310031595156\n",
      "Epoch:  5 1.9497294758641444\n",
      "Epoch:  6 1.929971507353376\n",
      "Epoch:  7 1.9202116182608198\n",
      "Epoch:  8 1.8825104800305625\n",
      "Epoch:  9 1.844579768735309\n",
      "Epoch:  10 1.8124470304149065\n",
      "Epoch:  11 1.9289473285970762\n",
      "Epoch:  12 1.8133748372395833\n",
      "Epoch:  13 1.7922881869382636\n",
      "Epoch:  14 1.7631640397301016\n",
      "Epoch:  15 1.7484606282655584\n",
      "Epoch:  16 1.9717839466508968\n",
      "Epoch:  17 3.215636216392813\n",
      "Epoch:  18 3.161638015924498\n",
      "Epoch:  19 3.1577226450276927\n",
      "Training Time: 34.998483419418335\n",
      "Train Accuracy: 0.07534722\n",
      "Test Accuracy: 0.06898148\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(init)\n",
    "       \n",
    "    # run our training data through the neural network for each epoch\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "      epoch_cost = 0\n",
    "      \n",
    "      # Run the training data through the neural network\n",
    "      for batch in range(batches):\n",
    "            \n",
    "          # Calculate the start and end indices for the next batch\n",
    "          begin = (batch * batch_size)\n",
    "          end   = (batch * batch_size) + batch_size\n",
    "            \n",
    "          # Get the next sequential batch from the training data\n",
    "          batch_xs, batch_ys = x_train[begin:end], y_train[begin:end]\n",
    "      \n",
    "          # Feed this batch through the neural network.\n",
    "          _, batch_cost = sess.run([optimizer, cost], feed_dict={X: batch_xs.T, Y: batch_ys.T, D: keep_prob, L: learning_rate})\n",
    "            \n",
    "          epoch_cost += batch_cost\n",
    "      \n",
    "      print(\"Epoch: \", epoch, epoch_cost / batches)\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Training Time:\", end - start)\n",
    "    \n",
    "    # Test the Model\n",
    "    \n",
    "    # Let's select the highest percent from the softmax output per image as the prediction.\n",
    "    prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "    \n",
    "    # Let's create another node for calculating the accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "    # Now let's run our trainingt images through the model to calculate our accuracy during training\n",
    "    # Note how we set the keep percent for the dropout rate to 1.0 (no dropout) when we are evaluating the accuracy.\n",
    "    print (\"Train Accuracy:\", accuracy.eval({X: x_train.T, Y: y_train.T, D: 1.0}))\n",
    "    \n",
    "    # Now let's run our test images through the model to calculate our accuracy on the test data\n",
    "    print (\"Test Accuracy:\", accuracy.eval({X: x_test.T, Y: y_test.T, D: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "The last three steps above is where our test data was ran through the model and produced how accurate our model was on the test data.\n",
    "\n",
    "After training the model, we created a node for prediction. This node compares two vectors, our predicted labels and our actual labels. Each vector is 10 elements long with a 1 in the predicted/actual digit location. So we are comparing the vectors. If they match (prediction matches actual), then we have a TRUE; otherwise a FALSE. That's how we are going to get our accuracy percentage calculated.\n",
    "\n",
    "Next, we create the node accuracy. This node is a cost function!\n",
    "\n",
    "We then run the accuracy node, feeding it the test images as the X variable and the test labels as the Y variable. This will result in the test images being ran through the model (which is in memory) and the corresponding output vectors evaluated against the actual labels of the test images (Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun with different learning rate\n",
    "\n",
    "Wah! We only got 3% accuracy with our learning rate at 0.5\n",
    "\n",
    "It appears we were converging, but more likely wildly bouncing back and forth on reducing the cost of each batch. This might be an infinite gradient problem. Let's try lowering the learning are by a magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun with different dropout\n",
    "\n",
    "Wow, we got 99.9% accuracy! We probably won't do better. The training and test accuracy are nearly the same, so we do not have an overfitting problem. But for the fun of it, let's increase the dropout rate and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really any difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have now successful designed and run DNN with Dropout, and feeding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
