{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Wine Dataset\n",
    "- 13 features\n",
    "- Classifies wine into 3 classes\n",
    "- 178 samples\n",
    "- No Data Wrangling (Clean Data)\n",
    "- Feature Scaling using Standarization\n",
    "- Classification using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries for Machine Learning\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sciket learn builtin wine dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, the scikit learn example datasets datatype is not a numpy array or panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The features are accessed with the property 'data' and the label (i.e., classification) with the property 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The features and labels are numpy arrays\n",
    "type(X)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the contents of the X (Features) and y (Labels) arrays have 178 samples each, and the X array has dimensionality of 13\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in training and test data\n",
    "- 70% training, 30% test\n",
    "- random selection (non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine, y,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data using Standardization\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.18700000e+01,   4.31000000e+00,   2.39000000e+00, ...,\n",
       "          7.50000000e-01,   3.64000000e+00,   3.80000000e+02],\n",
       "       [  1.21700000e+01,   1.45000000e+00,   2.53000000e+00, ...,\n",
       "          1.45000000e+00,   2.23000000e+00,   3.55000000e+02],\n",
       "       [  1.23400000e+01,   2.45000000e+00,   2.46000000e+00, ...,\n",
       "          8.00000000e-01,   3.38000000e+00,   4.38000000e+02],\n",
       "       ..., \n",
       "       [  1.27200000e+01,   1.81000000e+00,   2.20000000e+00, ...,\n",
       "          1.16000000e+00,   3.14000000e+00,   7.14000000e+02],\n",
       "       [  1.41200000e+01,   1.48000000e+00,   2.32000000e+00, ...,\n",
       "          1.17000000e+00,   2.82000000e+00,   1.28000000e+03],\n",
       "       [  1.24700000e+01,   1.52000000e+00,   2.20000000e+00, ...,\n",
       "          1.16000000e+00,   2.63000000e+00,   9.37000000e+02]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data before scaling\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of the Scaler Class\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note, fit will scale the data and transform will transform the data back into a numpy_array.\n",
    "# Since the scale has already been fitted with the X_train data, for X_test we only need to do a transform.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4421205 ,  1.8516745 ,  0.17426739, ..., -0.87833289,\n",
       "         1.37995589, -1.15691894],\n",
       "       [-1.07414682, -0.73489335,  0.70876951, ...,  2.11191244,\n",
       "        -0.5311054 , -1.23613021],\n",
       "       [-0.8656284 ,  0.16950101,  0.44151845, ..., -0.66474394,\n",
       "         1.02756161, -0.97314879],\n",
       "       ..., \n",
       "       [-0.39952841, -0.40931138, -0.55112833, ...,  0.87309652,\n",
       "         0.70227458, -0.09865636],\n",
       "       [ 1.31768209, -0.70776152, -0.09298366, ...,  0.91581431,\n",
       "         0.26855854,  1.69468681],\n",
       "       [-0.70617314, -0.67158574, -0.55112833, ...,  0.87309652,\n",
       "         0.01103965,  0.60790817]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data after it has been scaled\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's classify the training data to build a model using the ensemble method - Random Forest\n",
    "- n_estimators: the number of trees\n",
    "- criterion: method to split the data\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=101, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model (using 5 trees)\n",
    "model = RandomForestClassifier( n_estimators = 5, criterion = 'entropy', random_state = 101 )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the model to make predictions with the test data\n",
    "- Run the test data through the model to prediction the label (classification)\n",
    "- Compare the predicted values to the actual values\n",
    "- Determine accuracy of our model from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 2, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 1, 2, 1,\n",
       "       1, 2, 2, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the predicted values\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 1, 2, 1,\n",
       "       1, 2, 2, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the actual values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the accuracy of our predictions with the test data\n",
    "- Display matrix of shape nclasses X nclasses\n",
    "- The number of correct predictions per class will be along the diagonal.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix with the actual and predicted values\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  1,  0],\n",
       "       [ 0, 22,  0],\n",
       "       [ 0,  1, 12]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results (52 correct, 2 incorrect)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our accuracy\n",
    "accuracy = 52 / 54\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
